{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1qt1NtIejP-k",
    "outputId": "c5fab15d-a878-40dd-9480-074ff04ff809"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RnYXOMjz-RAX"
   },
   "source": [
    "# **Basics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AzALPz9MDY5g"
   },
   "outputs": [],
   "source": [
    "!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yZf-G14LEkHe",
    "outputId": "dc7f1fbb-4b27-496b-8a4f-3decc9beddba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_data  spark-3.1.2-bin-hadoop2.7.tgz\n"
     ]
    }
   ],
   "source": [
    "# get file url from the spark website\n",
    "!wget -q https://mirrors.estointernet.in/apache/spark/spark-3.1.2/spark-3.1.2-bin-hadoop2.7.tgz\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IUBY0jpPGrb-"
   },
   "outputs": [],
   "source": [
    "!tar xf spark-3.1.2-bin-hadoop2.7.tgz\n",
    "!pip install -q findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C1yIxxEpEvVU"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.2-bin-hadoop2.7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0eZd4K1zE0LE",
    "outputId": "8cb5f081-2cdd-4626-8d23-576c7e123627"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\work\\\\spark-2.4.8-bin-hadoop2.7'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HFCcB-bg-cBt"
   },
   "source": [
    "# **Assignment**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SrvpETThqa--"
   },
   "source": [
    "Dataset is [here](https://www.kaggle.com/benroshan/ecommerce-data?select=Order+Details.csv).\n",
    "\n",
    "**Questions:**\n",
    "1. In which order, there was maximum loss and in which order, there was maximum profit?\n",
    "\n",
    "2. Which category has been the most profitable and the least profitable (maybe have caused a loss as well)?\n",
    "\n",
    "3. From which state, most orders have been placed? \n",
    "\n",
    "4. Which category of product has been sold the most?\n",
    "\n",
    "5. For which all months, the sales target have been achieved? So, for each month, there's a sales target for each category. Find out for which category and which month, the sales target was achieved and not achieved.\n",
    "\n",
    "6. Which customer has spent the most amount on the website?\n",
    "\n",
    "## **Reading the Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "rQHo_gvsIIsB"
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as f\n",
    "\n",
    "\n",
    "spark = SparkSession.builder.master('local[1]').appName('E-commerce').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "3p0YCoUHI9Ga"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import FloatType, StringType, StructType, StructField, IntegerType, DateType\n",
    "\n",
    "\n",
    "order_deets_schema = StructType([\n",
    "                                 StructField(\"Order ID\", StringType(), True),\n",
    "                                 StructField(\"Amount\", FloatType(), True),\n",
    "                                 StructField(\"Profit\", FloatType(), True),\n",
    "                                 StructField(\"Quantity\", IntegerType(), True),\n",
    "                                 StructField(\"Category\", StringType(), True),\n",
    "                                 StructField(\"Sub-category\", StringType(), True)\n",
    "])\n",
    "orders_schema = StructType([\n",
    "                            StructField(\"Order ID\", StringType(), True),\n",
    "                            StructField(\"Order Date\", DateType(), True),\n",
    "                            StructField(\"CustomerName\", StringType(), True),\n",
    "                            StructField(\"State\", StringType(), True),\n",
    "                            StructField(\"City\", StringType(), True),\n",
    "])\n",
    "target_schema = StructType([\n",
    "                            StructField(\"Month of Order Date\", StringType(), True),\n",
    "                            StructField(\"Category\", StringType(), True),\n",
    "                            StructField(\"Target\", FloatType(), True),\n",
    "])\n",
    "order_deets_df = spark.read.option(\"dateFormat\", \"dd-MM-yyyy\").csv(\"archive/order_details.csv\", header = True, schema = order_deets_schema).dropna()\n",
    "orders_df = spark.read.option(\"dateFormat\", \"dd-MM-yyyy\").csv(\"archive/orders.csv\", header = True, schema = orders_schema)\n",
    "target_df = spark.read.option(\"dateFormat\", \"dd-MM-yyyy\").csv(\"archive/target.csv\", header = True, schema = target_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+------------+-----------------+------------------+\n",
      "|Order ID|Order Date|CustomerName|            State|              City|\n",
      "+--------+----------+------------+-----------------+------------------+\n",
      "| B-25601|2018-04-01|      Bharat|          Gujarat|         Ahmedabad|\n",
      "| B-25602|2018-04-01|       Pearl|      Maharashtra|              Pune|\n",
      "| B-25603|2018-04-03|       Jahan|   Madhya Pradesh|            Bhopal|\n",
      "| B-25604|2018-04-03|      Divsha|        Rajasthan|            Jaipur|\n",
      "| B-25605|2018-04-05|     Kasheen|      West Bengal|           Kolkata|\n",
      "| B-25606|2018-04-06|       Hazel|        Karnataka|         Bangalore|\n",
      "| B-25607|2018-04-06|    Sonakshi|Jammu and Kashmir|           Kashmir|\n",
      "| B-25608|2018-04-08|     Aarushi|       Tamil Nadu|           Chennai|\n",
      "| B-25609|2018-04-09|      Jitesh|    Uttar Pradesh|           Lucknow|\n",
      "| B-25610|2018-04-09|      Yogesh|            Bihar|             Patna|\n",
      "| B-25611|2018-04-11|       Anita|          Kerala |Thiruvananthapuram|\n",
      "| B-25612|2018-04-12|   Shrichand|           Punjab|        Chandigarh|\n",
      "| B-25613|2018-04-12|      Mukesh|          Haryana|        Chandigarh|\n",
      "| B-25614|2018-04-13|     Vandana| Himachal Pradesh|             Simla|\n",
      "| B-25615|2018-04-15|      Bhavna|           Sikkim|           Gangtok|\n",
      "| B-25616|2018-04-15|       Kanak|              Goa|               Goa|\n",
      "| B-25617|2018-04-17|       Sagar|         Nagaland|            Kohima|\n",
      "| B-25618|2018-04-18|       Manju|   Andhra Pradesh|         Hyderabad|\n",
      "| B-25619|2018-04-18|      Ramesh|          Gujarat|         Ahmedabad|\n",
      "| B-25620|2018-04-20|      Sarita|      Maharashtra|              Pune|\n",
      "+--------+----------+------------+-----------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orders_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mUVvK3PqsWXh",
    "outputId": "4160e6f9-c0f7-454b-9d51-3b061ab1378d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Order ID: string (nullable = true)\n",
      " |-- Amount: float (nullable = true)\n",
      " |-- Profit: float (nullable = true)\n",
      " |-- Quantity: integer (nullable = true)\n",
      " |-- Category: string (nullable = true)\n",
      " |-- Sub-category: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- Order ID: string (nullable = true)\n",
      " |-- Order Date: date (nullable = true)\n",
      " |-- CustomerName: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- Month of Order Date: string (nullable = true)\n",
      " |-- Category: string (nullable = true)\n",
      " |-- Target: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "order_deets_df.printSchema()\n",
    "orders_df.printSchema()\n",
    "target_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wHwwzjgDsGUG"
   },
   "source": [
    "## **1. Max Loss and Max Profit Order**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "BmYEeVSBqLAX"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import sum\n",
    "\n",
    "\n",
    "order_grouped = order_deets_df.groupBy(\"Order ID\").agg(sum(\"Profit\").alias(\"Profit Per Order\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Lqi27cT6lVC"
   },
   "source": [
    "**Max Profit and Min Profit Using Order By**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n6feTyzn20Af",
    "outputId": "246ab254-13a2-4ab5-8f95-29b2b16f2e7a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Order ID='B-25973', Profit Per Order=1970.0),\n",
       " Row(Order ID='B-25855', Profit Per Order=1432.0),\n",
       " Row(Order ID='B-25656', Profit Per Order=1021.0),\n",
       " Row(Order ID='B-26093', Profit Per Order=1020.0),\n",
       " Row(Order ID='B-25761', Profit Per Order=984.0),\n",
       " Row(Order ID='B-25602', Profit Per Order=975.0),\n",
       " Row(Order ID='B-25853', Profit Per Order=970.0),\n",
       " Row(Order ID='B-25923', Profit Per Order=966.0),\n",
       " Row(Order ID='B-26051', Profit Per Order=906.0),\n",
       " Row(Order ID='B-26073', Profit Per Order=889.0),\n",
       " Row(Order ID='B-25830', Profit Per Order=873.0),\n",
       " Row(Order ID='B-25858', Profit Per Order=868.0),\n",
       " Row(Order ID='B-25993', Profit Per Order=864.0),\n",
       " Row(Order ID='B-26099', Profit Per Order=859.0),\n",
       " Row(Order ID='B-25803', Profit Per Order=820.0),\n",
       " Row(Order ID='B-25862', Profit Per Order=745.0),\n",
       " Row(Order ID='B-25850', Profit Per Order=685.0),\n",
       " Row(Order ID='B-26055', Profit Per Order=683.0),\n",
       " Row(Order ID='B-25878', Profit Per Order=672.0),\n",
       " Row(Order ID='B-25955', Profit Per Order=669.0),\n",
       " Row(Order ID='B-25964', Profit Per Order=660.0),\n",
       " Row(Order ID='B-26085', Profit Per Order=653.0),\n",
       " Row(Order ID='B-25959', Profit Per Order=627.0),\n",
       " Row(Order ID='B-25877', Profit Per Order=609.0),\n",
       " Row(Order ID='B-26028', Profit Per Order=583.0),\n",
       " Row(Order ID='B-26006', Profit Per Order=573.0),\n",
       " Row(Order ID='B-25854', Profit Per Order=526.0),\n",
       " Row(Order ID='B-25951', Profit Per Order=516.0),\n",
       " Row(Order ID='B-25935', Profit Per Order=512.0),\n",
       " Row(Order ID='B-26048', Profit Per Order=505.0),\n",
       " Row(Order ID='B-25919', Profit Per Order=501.0),\n",
       " Row(Order ID='B-26023', Profit Per Order=490.0),\n",
       " Row(Order ID='B-25839', Profit Per Order=486.0),\n",
       " Row(Order ID='B-25873', Profit Per Order=455.0),\n",
       " Row(Order ID='B-26053', Profit Per Order=454.0),\n",
       " Row(Order ID='B-25845', Profit Per Order=451.0),\n",
       " Row(Order ID='B-25909', Profit Per Order=450.0),\n",
       " Row(Order ID='B-26050', Profit Per Order=440.0),\n",
       " Row(Order ID='B-25629', Profit Per Order=421.0),\n",
       " Row(Order ID='B-25885', Profit Per Order=421.0),\n",
       " Row(Order ID='B-25999', Profit Per Order=420.0),\n",
       " Row(Order ID='B-25943', Profit Per Order=420.0),\n",
       " Row(Order ID='B-26057', Profit Per Order=404.0),\n",
       " Row(Order ID='B-26054', Profit Per Order=402.0),\n",
       " Row(Order ID='B-25881', Profit Per Order=400.0),\n",
       " Row(Order ID='B-25970', Profit Per Order=398.0),\n",
       " Row(Order ID='B-25747', Profit Per Order=395.0),\n",
       " Row(Order ID='B-25898', Profit Per Order=394.0),\n",
       " Row(Order ID='B-25953', Profit Per Order=391.0),\n",
       " Row(Order ID='B-25838', Profit Per Order=390.0),\n",
       " Row(Order ID='B-26061', Profit Per Order=387.0),\n",
       " Row(Order ID='B-25825', Profit Per Order=386.0),\n",
       " Row(Order ID='B-25823', Profit Per Order=380.0),\n",
       " Row(Order ID='B-25981', Profit Per Order=377.0),\n",
       " Row(Order ID='B-25893', Profit Per Order=376.0),\n",
       " Row(Order ID='B-25842', Profit Per Order=370.0),\n",
       " Row(Order ID='B-25755', Profit Per Order=354.0),\n",
       " Row(Order ID='B-25937', Profit Per Order=352.0),\n",
       " Row(Order ID='B-26098', Profit Per Order=350.0),\n",
       " Row(Order ID='B-25851', Profit Per Order=343.0),\n",
       " Row(Order ID='B-25995', Profit Per Order=342.0),\n",
       " Row(Order ID='B-25810', Profit Per Order=339.0),\n",
       " Row(Order ID='B-25929', Profit Per Order=316.0),\n",
       " Row(Order ID='B-25986', Profit Per Order=310.0),\n",
       " Row(Order ID='B-26070', Profit Per Order=310.0),\n",
       " Row(Order ID='B-25847', Profit Per Order=296.0),\n",
       " Row(Order ID='B-25952', Profit Per Order=295.0),\n",
       " Row(Order ID='B-25852', Profit Per Order=290.0),\n",
       " Row(Order ID='B-25903', Profit Per Order=287.0),\n",
       " Row(Order ID='B-26035', Profit Per Order=285.0),\n",
       " Row(Order ID='B-25868', Profit Per Order=278.0),\n",
       " Row(Order ID='B-25996', Profit Per Order=275.0),\n",
       " Row(Order ID='B-26076', Profit Per Order=275.0),\n",
       " Row(Order ID='B-25950', Profit Per Order=268.0),\n",
       " Row(Order ID='B-25857', Profit Per Order=264.0),\n",
       " Row(Order ID='B-25826', Profit Per Order=261.0),\n",
       " Row(Order ID='B-26100', Profit Per Order=256.0),\n",
       " Row(Order ID='B-25831', Profit Per Order=254.0),\n",
       " Row(Order ID='B-25859', Profit Per Order=253.0),\n",
       " Row(Order ID='B-26000', Profit Per Order=253.0),\n",
       " Row(Order ID='B-25969', Profit Per Order=251.0),\n",
       " Row(Order ID='B-25997', Profit Per Order=247.0),\n",
       " Row(Order ID='B-25667', Profit Per Order=245.0),\n",
       " Row(Order ID='B-26052', Profit Per Order=245.0),\n",
       " Row(Order ID='B-25902', Profit Per Order=243.0),\n",
       " Row(Order ID='B-25752', Profit Per Order=241.0),\n",
       " Row(Order ID='B-25887', Profit Per Order=240.0),\n",
       " Row(Order ID='B-25974', Profit Per Order=240.0),\n",
       " Row(Order ID='B-25897', Profit Per Order=239.0),\n",
       " Row(Order ID='B-26033', Profit Per Order=237.0),\n",
       " Row(Order ID='B-25966', Profit Per Order=234.0),\n",
       " Row(Order ID='B-26056', Profit Per Order=225.0),\n",
       " Row(Order ID='B-25888', Profit Per Order=219.0),\n",
       " Row(Order ID='B-26067', Profit Per Order=216.0),\n",
       " Row(Order ID='B-25870', Profit Per Order=208.0),\n",
       " Row(Order ID='B-25890', Profit Per Order=207.0),\n",
       " Row(Order ID='B-25814', Profit Per Order=204.0),\n",
       " Row(Order ID='B-25813', Profit Per Order=202.0),\n",
       " Row(Order ID='B-26078', Profit Per Order=202.0),\n",
       " Row(Order ID='B-25840', Profit Per Order=199.0),\n",
       " Row(Order ID='B-26030', Profit Per Order=199.0),\n",
       " Row(Order ID='B-25786', Profit Per Order=196.0),\n",
       " Row(Order ID='B-25717', Profit Per Order=193.0),\n",
       " Row(Order ID='B-25896', Profit Per Order=190.0),\n",
       " Row(Order ID='B-26034', Profit Per Order=183.0),\n",
       " Row(Order ID='B-26019', Profit Per Order=175.0),\n",
       " Row(Order ID='B-25930', Profit Per Order=173.0),\n",
       " Row(Order ID='B-25914', Profit Per Order=165.0),\n",
       " Row(Order ID='B-26045', Profit Per Order=157.0),\n",
       " Row(Order ID='B-25989', Profit Per Order=156.0),\n",
       " Row(Order ID='B-25961', Profit Per Order=154.0),\n",
       " Row(Order ID='B-25968', Profit Per Order=154.0),\n",
       " Row(Order ID='B-25718', Profit Per Order=146.0),\n",
       " Row(Order ID='B-25979', Profit Per Order=144.0),\n",
       " Row(Order ID='B-25904', Profit Per Order=143.0),\n",
       " Row(Order ID='B-26043', Profit Per Order=143.0),\n",
       " Row(Order ID='B-25828', Profit Per Order=141.0),\n",
       " Row(Order ID='B-26009', Profit Per Order=140.0),\n",
       " Row(Order ID='B-25886', Profit Per Order=139.0),\n",
       " Row(Order ID='B-25663', Profit Per Order=138.0),\n",
       " Row(Order ID='B-25715', Profit Per Order=137.0),\n",
       " Row(Order ID='B-26014', Profit Per Order=136.0),\n",
       " Row(Order ID='B-25900', Profit Per Order=132.0),\n",
       " Row(Order ID='B-25954', Profit Per Order=131.0),\n",
       " Row(Order ID='B-25856', Profit Per Order=130.0),\n",
       " Row(Order ID='B-26002', Profit Per Order=128.0),\n",
       " Row(Order ID='B-25618', Profit Per Order=127.0),\n",
       " Row(Order ID='B-26040', Profit Per Order=126.0),\n",
       " Row(Order ID='B-25849', Profit Per Order=123.0),\n",
       " Row(Order ID='B-25918', Profit Per Order=122.0),\n",
       " Row(Order ID='B-26096', Profit Per Order=121.0),\n",
       " Row(Order ID='B-25785', Profit Per Order=121.0),\n",
       " Row(Order ID='B-26086', Profit Per Order=120.0),\n",
       " Row(Order ID='B-26087', Profit Per Order=119.0),\n",
       " Row(Order ID='B-26003', Profit Per Order=117.0),\n",
       " Row(Order ID='B-25843', Profit Per Order=117.0),\n",
       " Row(Order ID='B-26004', Profit Per Order=117.0),\n",
       " Row(Order ID='B-25832', Profit Per Order=116.0),\n",
       " Row(Order ID='B-26018', Profit Per Order=115.0),\n",
       " Row(Order ID='B-25816', Profit Per Order=113.0),\n",
       " Row(Order ID='B-25636', Profit Per Order=113.0),\n",
       " Row(Order ID='B-25685', Profit Per Order=112.0),\n",
       " Row(Order ID='B-25772', Profit Per Order=106.0),\n",
       " Row(Order ID='B-26020', Profit Per Order=102.0),\n",
       " Row(Order ID='B-26038', Profit Per Order=100.0),\n",
       " Row(Order ID='B-25984', Profit Per Order=97.0),\n",
       " Row(Order ID='B-26058', Profit Per Order=97.0),\n",
       " Row(Order ID='B-25901', Profit Per Order=95.0),\n",
       " Row(Order ID='B-25895', Profit Per Order=93.0),\n",
       " Row(Order ID='B-25939', Profit Per Order=92.0),\n",
       " Row(Order ID='B-25619', Profit Per Order=90.0),\n",
       " Row(Order ID='B-26091', Profit Per Order=89.0),\n",
       " Row(Order ID='B-25817', Profit Per Order=89.0),\n",
       " Row(Order ID='B-25863', Profit Per Order=87.0),\n",
       " Row(Order ID='B-25977', Profit Per Order=84.0),\n",
       " Row(Order ID='B-25971', Profit Per Order=83.0),\n",
       " Row(Order ID='B-25791', Profit Per Order=80.0),\n",
       " Row(Order ID='B-25883', Profit Per Order=80.0),\n",
       " Row(Order ID='B-25848', Profit Per Order=79.0),\n",
       " Row(Order ID='B-25891', Profit Per Order=79.0),\n",
       " Row(Order ID='B-26026', Profit Per Order=78.0),\n",
       " Row(Order ID='B-25809', Profit Per Order=78.0),\n",
       " Row(Order ID='B-26008', Profit Per Order=78.0),\n",
       " Row(Order ID='B-25949', Profit Per Order=77.0),\n",
       " Row(Order ID='B-25683', Profit Per Order=76.0),\n",
       " Row(Order ID='B-25818', Profit Per Order=73.0),\n",
       " Row(Order ID='B-25659', Profit Per Order=72.0),\n",
       " Row(Order ID='B-26007', Profit Per Order=72.0),\n",
       " Row(Order ID='B-26060', Profit Per Order=68.0),\n",
       " Row(Order ID='B-26037', Profit Per Order=68.0),\n",
       " Row(Order ID='B-25947', Profit Per Order=68.0),\n",
       " Row(Order ID='B-26021', Profit Per Order=68.0),\n",
       " Row(Order ID='B-25956', Profit Per Order=67.0),\n",
       " Row(Order ID='B-25727', Profit Per Order=66.0),\n",
       " Row(Order ID='B-25836', Profit Per Order=65.0),\n",
       " Row(Order ID='B-25985', Profit Per Order=65.0),\n",
       " Row(Order ID='B-25889', Profit Per Order=64.0),\n",
       " Row(Order ID='B-25957', Profit Per Order=62.0),\n",
       " Row(Order ID='B-25804', Profit Per Order=62.0),\n",
       " Row(Order ID='B-25894', Profit Per Order=62.0),\n",
       " Row(Order ID='B-26016', Profit Per Order=61.0),\n",
       " Row(Order ID='B-25771', Profit Per Order=59.0),\n",
       " Row(Order ID='B-25958', Profit Per Order=57.0),\n",
       " Row(Order ID='B-26015', Profit Per Order=55.0),\n",
       " Row(Order ID='B-25757', Profit Per Order=55.0),\n",
       " Row(Order ID='B-25874', Profit Per Order=54.0),\n",
       " Row(Order ID='B-25924', Profit Per Order=54.0),\n",
       " Row(Order ID='B-25811', Profit Per Order=52.0),\n",
       " Row(Order ID='B-25867', Profit Per Order=52.0),\n",
       " Row(Order ID='B-26083', Profit Per Order=50.0),\n",
       " Row(Order ID='B-26094', Profit Per Order=50.0),\n",
       " Row(Order ID='B-25837', Profit Per Order=50.0),\n",
       " Row(Order ID='B-25905', Profit Per Order=50.0),\n",
       " Row(Order ID='B-25819', Profit Per Order=49.0),\n",
       " Row(Order ID='B-25991', Profit Per Order=48.0),\n",
       " Row(Order ID='B-25635', Profit Per Order=48.0),\n",
       " Row(Order ID='B-25770', Profit Per Order=48.0),\n",
       " Row(Order ID='B-25812', Profit Per Order=47.0),\n",
       " Row(Order ID='B-25972', Profit Per Order=47.0),\n",
       " Row(Order ID='B-25833', Profit Per Order=47.0),\n",
       " Row(Order ID='B-25748', Profit Per Order=46.0),\n",
       " Row(Order ID='B-25620', Profit Per Order=46.0),\n",
       " Row(Order ID='B-26072', Profit Per Order=44.0),\n",
       " Row(Order ID='B-26036', Profit Per Order=44.0),\n",
       " Row(Order ID='B-26011', Profit Per Order=44.0),\n",
       " Row(Order ID='B-25694', Profit Per Order=43.0),\n",
       " Row(Order ID='B-26064', Profit Per Order=43.0),\n",
       " Row(Order ID='B-26089', Profit Per Order=42.0),\n",
       " Row(Order ID='B-25614', Profit Per Order=42.0),\n",
       " Row(Order ID='B-25684', Profit Per Order=42.0),\n",
       " Row(Order ID='B-25992', Profit Per Order=41.0),\n",
       " Row(Order ID='B-25899', Profit Per Order=41.0),\n",
       " Row(Order ID='B-25941', Profit Per Order=41.0),\n",
       " Row(Order ID='B-25835', Profit Per Order=39.0),\n",
       " Row(Order ID='B-25944', Profit Per Order=38.0),\n",
       " Row(Order ID='B-25621', Profit Per Order=38.0),\n",
       " Row(Order ID='B-25829', Profit Per Order=38.0),\n",
       " Row(Order ID='B-25824', Profit Per Order=38.0),\n",
       " Row(Order ID='B-25794', Profit Per Order=37.0),\n",
       " Row(Order ID='B-25880', Profit Per Order=37.0),\n",
       " Row(Order ID='B-25967', Profit Per Order=37.0),\n",
       " Row(Order ID='B-26080', Profit Per Order=35.0),\n",
       " Row(Order ID='B-26010', Profit Per Order=34.0),\n",
       " Row(Order ID='B-26039', Profit Per Order=34.0),\n",
       " Row(Order ID='B-26068', Profit Per Order=33.0),\n",
       " Row(Order ID='B-25934', Profit Per Order=33.0),\n",
       " Row(Order ID='B-25990', Profit Per Order=32.0),\n",
       " Row(Order ID='B-25892', Profit Per Order=30.0),\n",
       " Row(Order ID='B-25638', Profit Per Order=29.0),\n",
       " Row(Order ID='B-25692', Profit Per Order=28.0),\n",
       " Row(Order ID='B-25879', Profit Per Order=28.0),\n",
       " Row(Order ID='B-26049', Profit Per Order=28.0),\n",
       " Row(Order ID='B-25864', Profit Per Order=28.0),\n",
       " Row(Order ID='B-26001', Profit Per Order=28.0),\n",
       " Row(Order ID='B-25906', Profit Per Order=27.0),\n",
       " Row(Order ID='B-25872', Profit Per Order=27.0),\n",
       " Row(Order ID='B-25642', Profit Per Order=26.0),\n",
       " Row(Order ID='B-25938', Profit Per Order=26.0),\n",
       " Row(Order ID='B-25916', Profit Per Order=26.0),\n",
       " Row(Order ID='B-25936', Profit Per Order=25.0),\n",
       " Row(Order ID='B-25908', Profit Per Order=25.0),\n",
       " Row(Order ID='B-25871', Profit Per Order=25.0),\n",
       " Row(Order ID='B-26025', Profit Per Order=25.0),\n",
       " Row(Order ID='B-25808', Profit Per Order=25.0),\n",
       " Row(Order ID='B-25928', Profit Per Order=25.0),\n",
       " Row(Order ID='B-25988', Profit Per Order=24.0),\n",
       " Row(Order ID='B-25860', Profit Per Order=24.0),\n",
       " Row(Order ID='B-25609', Profit Per Order=24.0),\n",
       " Row(Order ID='B-25948', Profit Per Order=23.0),\n",
       " Row(Order ID='B-26090', Profit Per Order=22.0),\n",
       " Row(Order ID='B-26066', Profit Per Order=22.0),\n",
       " Row(Order ID='B-25604', Profit Per Order=22.0),\n",
       " Row(Order ID='B-25691', Profit Per Order=22.0),\n",
       " Row(Order ID='B-25821', Profit Per Order=21.0),\n",
       " Row(Order ID='B-25913', Profit Per Order=21.0),\n",
       " Row(Order ID='B-26074', Profit Per Order=21.0),\n",
       " Row(Order ID='B-25827', Profit Per Order=21.0),\n",
       " Row(Order ID='B-25615', Profit Per Order=20.0),\n",
       " Row(Order ID='B-25882', Profit Per Order=19.0),\n",
       " Row(Order ID='B-26065', Profit Per Order=19.0),\n",
       " Row(Order ID='B-26024', Profit Per Order=18.0),\n",
       " Row(Order ID='B-26069', Profit Per Order=18.0),\n",
       " Row(Order ID='B-25922', Profit Per Order=18.0),\n",
       " Row(Order ID='B-25668', Profit Per Order=17.0),\n",
       " Row(Order ID='B-25746', Profit Per Order=16.0),\n",
       " Row(Order ID='B-26042', Profit Per Order=15.0),\n",
       " Row(Order ID='B-25805', Profit Per Order=15.0),\n",
       " Row(Order ID='B-25714', Profit Per Order=15.0),\n",
       " Row(Order ID='B-25607', Profit Per Order=15.0),\n",
       " Row(Order ID='B-26032', Profit Per Order=15.0),\n",
       " Row(Order ID='B-25911', Profit Per Order=15.0),\n",
       " Row(Order ID='B-26092', Profit Per Order=14.0),\n",
       " Row(Order ID='B-25637', Profit Per Order=14.0),\n",
       " Row(Order ID='B-25815', Profit Per Order=14.0),\n",
       " Row(Order ID='B-25866', Profit Per Order=14.0),\n",
       " Row(Order ID='B-25695', Profit Per Order=14.0),\n",
       " Row(Order ID='B-25876', Profit Per Order=14.0),\n",
       " Row(Order ID='B-25765', Profit Per Order=14.0),\n",
       " Row(Order ID='B-25822', Profit Per Order=13.0),\n",
       " Row(Order ID='B-25917', Profit Per Order=12.0),\n",
       " Row(Order ID='B-25624', Profit Per Order=12.0),\n",
       " Row(Order ID='B-26075', Profit Per Order=12.0),\n",
       " Row(Order ID='B-26047', Profit Per Order=12.0),\n",
       " Row(Order ID='B-25912', Profit Per Order=11.0),\n",
       " Row(Order ID='B-25980', Profit Per Order=11.0),\n",
       " Row(Order ID='B-25841', Profit Per Order=11.0),\n",
       " Row(Order ID='B-25907', Profit Per Order=11.0),\n",
       " Row(Order ID='B-25987', Profit Per Order=11.0),\n",
       " Row(Order ID='B-26077', Profit Per Order=11.0),\n",
       " Row(Order ID='B-26029', Profit Per Order=10.0),\n",
       " Row(Order ID='B-26013', Profit Per Order=10.0),\n",
       " Row(Order ID='B-25690', Profit Per Order=10.0),\n",
       " Row(Order ID='B-26044', Profit Per Order=10.0),\n",
       " Row(Order ID='B-26005', Profit Per Order=10.0),\n",
       " Row(Order ID='B-25719', Profit Per Order=10.0),\n",
       " Row(Order ID='B-25658', Profit Per Order=9.0),\n",
       " Row(Order ID='B-25869', Profit Per Order=9.0),\n",
       " Row(Order ID='B-26031', Profit Per Order=9.0),\n",
       " Row(Order ID='B-25963', Profit Per Order=8.0),\n",
       " Row(Order ID='B-25976', Profit Per Order=8.0),\n",
       " Row(Order ID='B-26027', Profit Per Order=8.0),\n",
       " Row(Order ID='B-25844', Profit Per Order=8.0),\n",
       " Row(Order ID='B-26012', Profit Per Order=8.0),\n",
       " Row(Order ID='B-25875', Profit Per Order=8.0),\n",
       " Row(Order ID='B-25946', Profit Per Order=7.0),\n",
       " Row(Order ID='B-25940', Profit Per Order=7.0),\n",
       " Row(Order ID='B-25927', Profit Per Order=7.0),\n",
       " Row(Order ID='B-25965', Profit Per Order=7.0),\n",
       " Row(Order ID='B-26017', Profit Per Order=7.0),\n",
       " Row(Order ID='B-25920', Profit Per Order=7.0),\n",
       " Row(Order ID='B-25846', Profit Per Order=7.0),\n",
       " Row(Order ID='B-26059', Profit Per Order=6.0),\n",
       " Row(Order ID='B-25807', Profit Per Order=6.0),\n",
       " Row(Order ID='B-25926', Profit Per Order=6.0),\n",
       " Row(Order ID='B-26082', Profit Per Order=5.0),\n",
       " Row(Order ID='B-26088', Profit Per Order=5.0),\n",
       " Row(Order ID='B-25834', Profit Per Order=5.0),\n",
       " Row(Order ID='B-25606', Profit Per Order=4.0),\n",
       " Row(Order ID='B-25784', Profit Per Order=4.0),\n",
       " Row(Order ID='B-26071', Profit Per Order=4.0),\n",
       " Row(Order ID='B-25788', Profit Per Order=3.0),\n",
       " Row(Order ID='B-25915', Profit Per Order=3.0),\n",
       " Row(Order ID='B-25982', Profit Per Order=3.0),\n",
       " Row(Order ID='B-26079', Profit Per Order=3.0),\n",
       " Row(Order ID='B-26046', Profit Per Order=3.0),\n",
       " Row(Order ID='B-25623', Profit Per Order=3.0),\n",
       " Row(Order ID='B-25884', Profit Per Order=2.0),\n",
       " Row(Order ID='B-25975', Profit Per Order=2.0),\n",
       " Row(Order ID='B-25820', Profit Per Order=1.0),\n",
       " Row(Order ID='B-26095', Profit Per Order=1.0),\n",
       " Row(Order ID='B-25605', Profit Per Order=0.0),\n",
       " Row(Order ID='B-25613', Profit Per Order=0.0),\n",
       " Row(Order ID='B-25671', Profit Per Order=0.0),\n",
       " Row(Order ID='B-25705', Profit Per Order=0.0),\n",
       " Row(Order ID='B-25716', Profit Per Order=0.0),\n",
       " Row(Order ID='B-25622', Profit Per Order=0.0),\n",
       " Row(Order ID='B-25865', Profit Per Order=-1.0),\n",
       " Row(Order ID='B-25677', Profit Per Order=-2.0),\n",
       " Row(Order ID='B-25632', Profit Per Order=-2.0),\n",
       " Row(Order ID='B-25758', Profit Per Order=-2.0),\n",
       " Row(Order ID='B-25790', Profit Per Order=-3.0),\n",
       " Row(Order ID='B-25769', Profit Per Order=-4.0),\n",
       " Row(Order ID='B-25670', Profit Per Order=-4.0),\n",
       " Row(Order ID='B-25628', Profit Per Order=-4.0),\n",
       " Row(Order ID='B-25732', Profit Per Order=-5.0),\n",
       " Row(Order ID='B-25641', Profit Per Order=-6.0),\n",
       " Row(Order ID='B-25707', Profit Per Order=-6.0),\n",
       " Row(Order ID='B-25774', Profit Per Order=-6.0),\n",
       " Row(Order ID='B-25647', Profit Per Order=-6.0),\n",
       " Row(Order ID='B-25741', Profit Per Order=-6.0),\n",
       " Row(Order ID='B-25994', Profit Per Order=-7.0),\n",
       " Row(Order ID='B-25736', Profit Per Order=-7.0),\n",
       " Row(Order ID='B-25721', Profit Per Order=-7.0),\n",
       " Row(Order ID='B-25742', Profit Per Order=-8.0),\n",
       " Row(Order ID='B-25646', Profit Per Order=-8.0),\n",
       " Row(Order ID='B-25722', Profit Per Order=-8.0),\n",
       " Row(Order ID='B-25759', Profit Per Order=-9.0),\n",
       " Row(Order ID='B-25945', Profit Per Order=-9.0),\n",
       " Row(Order ID='B-25735', Profit Per Order=-10.0),\n",
       " Row(Order ID='B-25706', Profit Per Order=-11.0),\n",
       " Row(Order ID='B-25674', Profit Per Order=-12.0),\n",
       " Row(Order ID='B-25932', Profit Per Order=-14.0),\n",
       " Row(Order ID='B-25672', Profit Per Order=-15.0),\n",
       " Row(Order ID='B-25737', Profit Per Order=-15.0),\n",
       " Row(Order ID='B-25978', Profit Per Order=-15.0),\n",
       " Row(Order ID='B-25925', Profit Per Order=-15.0),\n",
       " Row(Order ID='B-25775', Profit Per Order=-17.0),\n",
       " Row(Order ID='B-25725', Profit Per Order=-17.0),\n",
       " Row(Order ID='B-25709', Profit Per Order=-18.0),\n",
       " Row(Order ID='B-25766', Profit Per Order=-19.0),\n",
       " Row(Order ID='B-25734', Profit Per Order=-19.0),\n",
       " Row(Order ID='B-25776', Profit Per Order=-20.0),\n",
       " Row(Order ID='B-25795', Profit Per Order=-21.0),\n",
       " Row(Order ID='B-25962', Profit Per Order=-22.0),\n",
       " Row(Order ID='B-25782', Profit Per Order=-22.0),\n",
       " Row(Order ID='B-25942', Profit Per Order=-23.0),\n",
       " Row(Order ID='B-25680', Profit Per Order=-25.0),\n",
       " Row(Order ID='B-25792', Profit Per Order=-25.0),\n",
       " Row(Order ID='B-25649', Profit Per Order=-25.0),\n",
       " Row(Order ID='B-26041', Profit Per Order=-28.0),\n",
       " Row(Order ID='B-25998', Profit Per Order=-28.0),\n",
       " Row(Order ID='B-25720', Profit Per Order=-35.0),\n",
       " Row(Order ID='B-25931', Profit Per Order=-36.0),\n",
       " Row(Order ID='B-25801', Profit Per Order=-37.0),\n",
       " Row(Order ID='B-25861', Profit Per Order=-38.0),\n",
       " Row(Order ID='B-25627', Profit Per Order=-39.0),\n",
       " Row(Order ID='B-25780', Profit Per Order=-41.0),\n",
       " Row(Order ID='B-25783', Profit Per Order=-42.0),\n",
       " Row(Order ID='B-25740', Profit Per Order=-45.0),\n",
       " Row(Order ID='B-25687', Profit Per Order=-48.0),\n",
       " Row(Order ID='B-25616', Profit Per Order=-48.0),\n",
       " Row(Order ID='B-25679', Profit Per Order=-50.0),\n",
       " Row(Order ID='B-25724', Profit Per Order=-51.0),\n",
       " Row(Order ID='B-25763', Profit Per Order=-52.0),\n",
       " Row(Order ID='B-25612', Profit Per Order=-55.0),\n",
       " Row(Order ID='B-25739', Profit Per Order=-56.0),\n",
       " Row(Order ID='B-25711', Profit Per Order=-58.0),\n",
       " Row(Order ID='B-25751', Profit Per Order=-58.0),\n",
       " Row(Order ID='B-26062', Profit Per Order=-59.0),\n",
       " Row(Order ID='B-25611', Profit Per Order=-59.0),\n",
       " Row(Order ID='B-25733', Profit Per Order=-59.0),\n",
       " Row(Order ID='B-25800', Profit Per Order=-60.0),\n",
       " Row(Order ID='B-26084', Profit Per Order=-63.0),\n",
       " Row(Order ID='B-25704', Profit Per Order=-63.0),\n",
       " Row(Order ID='B-25713', Profit Per Order=-63.0),\n",
       " Row(Order ID='B-25669', Profit Per Order=-66.0),\n",
       " Row(Order ID='B-25921', Profit Per Order=-67.0),\n",
       " Row(Order ID='B-25699', Profit Per Order=-71.0),\n",
       " Row(Order ID='B-25682', Profit Per Order=-73.0),\n",
       " Row(Order ID='B-25678', Profit Per Order=-74.0),\n",
       " Row(Order ID='B-26063', Profit Per Order=-77.0),\n",
       " Row(Order ID='B-25648', Profit Per Order=-77.0),\n",
       " Row(Order ID='B-25660', Profit Per Order=-78.0),\n",
       " Row(Order ID='B-25749', Profit Per Order=-82.0),\n",
       " Row(Order ID='B-25634', Profit Per Order=-83.0),\n",
       " Row(Order ID='B-25631', Profit Per Order=-89.0),\n",
       " Row(Order ID='B-25644', Profit Per Order=-92.0),\n",
       " Row(Order ID='B-25675', Profit Per Order=-93.0),\n",
       " Row(Order ID='B-25701', Profit Per Order=-94.0),\n",
       " Row(Order ID='B-25723', Profit Per Order=-97.0),\n",
       " Row(Order ID='B-25789', Profit Per Order=-99.0),\n",
       " Row(Order ID='B-25662', Profit Per Order=-100.0),\n",
       " Row(Order ID='B-25700', Profit Per Order=-110.0),\n",
       " Row(Order ID='B-25738', Profit Per Order=-111.0),\n",
       " Row(Order ID='B-25665', Profit Per Order=-113.0),\n",
       " Row(Order ID='B-25806', Profit Per Order=-114.0),\n",
       " Row(Order ID='B-25767', Profit Per Order=-121.0),\n",
       " Row(Order ID='B-25983', Profit Per Order=-122.0),\n",
       " Row(Order ID='B-25726', Profit Per Order=-128.0),\n",
       " Row(Order ID='B-25764', Profit Per Order=-134.0),\n",
       " Row(Order ID='B-25710', Profit Per Order=-134.0),\n",
       " Row(Order ID='B-25960', Profit Per Order=-140.0),\n",
       " Row(Order ID='B-25708', Profit Per Order=-146.0),\n",
       " Row(Order ID='B-25673', Profit Per Order=-149.0),\n",
       " Row(Order ID='B-25639', Profit Per Order=-153.0),\n",
       " Row(Order ID='B-25731', Profit Per Order=-154.0),\n",
       " Row(Order ID='B-25777', Profit Per Order=-159.0),\n",
       " Row(Order ID='B-25643', Profit Per Order=-173.0),\n",
       " Row(Order ID='B-25603', Profit Per Order=-180.0),\n",
       " Row(Order ID='B-25654', Profit Per Order=-182.0),\n",
       " Row(Order ID='B-25760', Profit Per Order=-193.0),\n",
       " Row(Order ID='B-25645', Profit Per Order=-195.0),\n",
       " Row(Order ID='B-25696', Profit Per Order=-207.0),\n",
       " Row(Order ID='B-25630', Profit Per Order=-211.0),\n",
       " Row(Order ID='B-25793', Profit Per Order=-212.0),\n",
       " Row(Order ID='B-25633', Profit Per Order=-217.0),\n",
       " Row(Order ID='B-25664', Profit Per Order=-223.0),\n",
       " Row(Order ID='B-25799', Profit Per Order=-225.0),\n",
       " Row(Order ID='B-25753', Profit Per Order=-235.0),\n",
       " Row(Order ID='B-25743', Profit Per Order=-236.0),\n",
       " Row(Order ID='B-25651', Profit Per Order=-237.0),\n",
       " Row(Order ID='B-25744', Profit Per Order=-254.0),\n",
       " Row(Order ID='B-25773', Profit Per Order=-257.0),\n",
       " Row(Order ID='B-25910', Profit Per Order=-265.0),\n",
       " Row(Order ID='B-25617', Profit Per Order=-270.0),\n",
       " Row(Order ID='B-25728', Profit Per Order=-273.0),\n",
       " Row(Order ID='B-25712', Profit Per Order=-275.0),\n",
       " Row(Order ID='B-25661', Profit Per Order=-276.0),\n",
       " Row(Order ID='B-25750', Profit Per Order=-278.0),\n",
       " Row(Order ID='B-25625', Profit Per Order=-290.0),\n",
       " Row(Order ID='B-25626', Profit Per Order=-290.0),\n",
       " Row(Order ID='B-25697', Profit Per Order=-292.0),\n",
       " Row(Order ID='B-25657', Profit Per Order=-293.0),\n",
       " Row(Order ID='B-25745', Profit Per Order=-297.0),\n",
       " Row(Order ID='B-25676', Profit Per Order=-304.0),\n",
       " Row(Order ID='B-25787', Profit Per Order=-320.0),\n",
       " Row(Order ID='B-25652', Profit Per Order=-324.0),\n",
       " Row(Order ID='B-26081', Profit Per Order=-328.0),\n",
       " Row(Order ID='B-25688', Profit Per Order=-345.0),\n",
       " Row(Order ID='B-25640', Profit Per Order=-348.0),\n",
       " Row(Order ID='B-25702', Profit Per Order=-370.0),\n",
       " Row(Order ID='B-25689', Profit Per Order=-406.0),\n",
       " Row(Order ID='B-25653', Profit Per Order=-406.0),\n",
       " Row(Order ID='B-25729', Profit Per Order=-439.0),\n",
       " Row(Order ID='B-25768', Profit Per Order=-443.0),\n",
       " Row(Order ID='B-25703', Profit Per Order=-449.0),\n",
       " Row(Order ID='B-25655', Profit Per Order=-489.0),\n",
       " Row(Order ID='B-26097', Profit Per Order=-504.0),\n",
       " Row(Order ID='B-25762', Profit Per Order=-528.0),\n",
       " Row(Order ID='B-25693', Profit Per Order=-535.0),\n",
       " Row(Order ID='B-25778', Profit Per Order=-553.0),\n",
       " Row(Order ID='B-25933', Profit Per Order=-556.0),\n",
       " Row(Order ID='B-25796', Profit Per Order=-566.0),\n",
       " Row(Order ID='B-25686', Profit Per Order=-572.0),\n",
       " Row(Order ID='B-25681', Profit Per Order=-575.0),\n",
       " Row(Order ID='B-25802', Profit Per Order=-647.0),\n",
       " Row(Order ID='B-25698', Profit Per Order=-652.0),\n",
       " Row(Order ID='B-25754', Profit Per Order=-676.0),\n",
       " Row(Order ID='B-25730', Profit Per Order=-685.0),\n",
       " Row(Order ID='B-25610', Profit Per Order=-746.0),\n",
       " Row(Order ID='B-25650', Profit Per Order=-799.0),\n",
       " Row(Order ID='B-25756', Profit Per Order=-870.0),\n",
       " Row(Order ID='B-25781', Profit Per Order=-900.0),\n",
       " Row(Order ID='B-25666', Profit Per Order=-916.0),\n",
       " Row(Order ID='B-25797', Profit Per Order=-927.0),\n",
       " Row(Order ID='B-25779', Profit Per Order=-980.0),\n",
       " Row(Order ID='B-25601', Profit Per Order=-1218.0),\n",
       " Row(Order ID='B-26022', Profit Per Order=-1303.0),\n",
       " Row(Order ID='B-25608', Profit Per Order=-1456.0),\n",
       " Row(Order ID='B-25798', Profit Per Order=-1836.0)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order_pl = order_grouped.orderBy(\"Profit Per Order\", ascending = False)\n",
    "order_pl.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(Order ID='B-25973', Profit Per Order=1970.0)\n",
      "Row(Order ID='B-25798', Profit Per Order=-1836.0)\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "print(order_pl.first())\n",
    "\n",
    "last=order_pl.orderBy(F.monotonically_increasing_id().desc())\n",
    "print(last.first())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Y9JTVVx6vn9"
   },
   "source": [
    "**Max Profit and Min Profit using Max and Min Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NoBmh-5f3sP_",
    "outputId": "85d44410-2dce-404f-d61b-ff75e7c0997e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|Max Profit|\n",
      "+----------+\n",
      "|    1970.0|\n",
      "+----------+\n",
      "\n",
      "+----------+\n",
      "|Min Profit|\n",
      "+----------+\n",
      "|   -1836.0|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "order_grouped.agg(f.max(f.col(\"Profit Per Order\")).alias(\"Max Profit\")).show()\n",
    "order_grouped.agg(f.min(f.col(\"Profit Per Order\")).alias(\"Min Profit\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KXSggPbi61Y9"
   },
   "source": [
    "## **2. Max Profit and Min Profit Category**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "eEgKci3Z60zS"
   },
   "outputs": [],
   "source": [
    "category_pl = order_deets_df.groupBy(\"Category\").agg(sum(\"Profit\").alias(\"Profit Per Category\")).orderBy(\"Profit Per Category\", ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JtZ-FPBJ8q9b"
   },
   "source": [
    "**Most Profitable Category**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w4I96oKp8DN8",
    "outputId": "43922ff8-d4e0-4576-bd83-a09bbe3bfded"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(Category='Clothing', Profit Per Category=11163.0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_pl.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GGu8L0MC8vXi"
   },
   "source": [
    "**Least Profitable Category**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K3zNmxqs80lC",
    "outputId": "36aeacc1-ed1d-4359-d3de-aecec08b4efe"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'tail'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\DMS240~1\\AppData\\Local\\Temp/ipykernel_20128/2776955239.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcategory_pl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtail\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\work\\spark-2.4.8-bin-hadoop2.7\\python\\pyspark\\sql\\dataframe.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1303\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1304\u001b[0m             raise AttributeError(\n\u001b[1;32m-> 1305\u001b[1;33m                 \"'%s' object has no attribute '%s'\" % (self.__class__.__name__, name))\n\u001b[0m\u001b[0;32m   1306\u001b[0m         \u001b[0mjc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1307\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mColumn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'tail'"
     ]
    }
   ],
   "source": [
    "category_pl.tail(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "apRDnrM0AO74"
   },
   "source": [
    "## **3. Most Orders By State**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "bJ_g7zZpAD50"
   },
   "outputs": [],
   "source": [
    "state_order = orders_df.groupBy(\"State\").count().orderBy(\"Count\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mlZhNkVnAwQT",
    "outputId": "d9208a09-c543-46b2-a750-1c1e8fc25d77"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(State='Madhya Pradesh', count=101)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_order.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jgnWZHOUfvYn"
   },
   "source": [
    "## **4. Most Sold Categries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "Idb1wKycgDli"
   },
   "outputs": [],
   "source": [
    "category_count = order_deets_df.groupBy(\"Category\").agg(sum(\"Quantity\").alias(\"Products Sold Per Cateory\")).orderBy(\"Products Sold Per Cateory\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C6dDt1BzgwGd",
    "outputId": "5d17832c-69d7-481b-fa04-ef053bc1875a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(Category='Clothing', Products Sold Per Cateory=3516)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_count.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gBskJl_wg5rI"
   },
   "source": [
    "## **5. Target Achieved**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "eM650MfumXoi"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "not all arguments converted during string formatting",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\DMS240~1\\AppData\\Local\\Temp/ipykernel_20128/4023231666.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# Getting order timestamps\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0morders_na\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0morders_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Order ID\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Order Date\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;33m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Order Year\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmod_year\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Order Date\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Order Month\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_month\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Order Date\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\DMS240~1\\AppData\\Local\\Temp/ipykernel_20128/4023231666.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmonths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Jan\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Feb\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Mar\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Apr\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"May\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Jun\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Jul\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Aug\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Sep\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Oct\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Nov\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Dec\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mto_month\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmonths\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmod_year\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m2000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: not all arguments converted during string formatting"
     ]
    }
   ],
   "source": [
    "months = [\"\", \"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"]\n",
    "to_month = f.udf(lambda x: str(months[x]))\n",
    "mod_year = f.udf(lambda x: str(x % 2000))\n",
    "\n",
    "\n",
    "# Getting order timestamps\n",
    "orders_na = orders_df.select(\"Order ID\", \"Order Date\")\\\n",
    ".withColumn(\"Order Year\", mod_year(f.year(\"Order Date\")))\\\n",
    ".withColumn(\"Order Month\", to_month(f.month(\"Order Date\")))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o1021.collectToPython.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 72.0 failed 1 times, most recent failure: Lost task 0.0 in stage 72.0 (TID 5068, localhost, executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"C:\\work\\spark-2.4.8-bin-hadoop2.7\\python\\lib\\pyspark.zip\\pyspark\\worker.py\", line 377, in main\n  File \"C:\\work\\spark-2.4.8-bin-hadoop2.7\\python\\lib\\pyspark.zip\\pyspark\\worker.py\", line 372, in process\n  File \"C:\\work\\spark-2.4.8-bin-hadoop2.7\\python\\lib\\pyspark.zip\\pyspark\\serializers.py\", line 352, in dump_stream\n    self.serializer.dump_stream(self._batched(iterator), stream)\n  File \"C:\\work\\spark-2.4.8-bin-hadoop2.7\\python\\lib\\pyspark.zip\\pyspark\\serializers.py\", line 142, in dump_stream\n    for obj in iterator:\n  File \"C:\\work\\spark-2.4.8-bin-hadoop2.7\\python\\lib\\pyspark.zip\\pyspark\\serializers.py\", line 341, in _batched\n    for item in iterator:\n  File \"<string>\", line 1, in <lambda>\n  File \"C:\\work\\spark-2.4.8-bin-hadoop2.7\\python\\lib\\pyspark.zip\\pyspark\\worker.py\", line 85, in <lambda>\n  File \"C:\\work\\spark-2.4.8-bin-hadoop2.7\\python\\lib\\pyspark.zip\\pyspark\\util.py\", line 99, in wrapper\n    return f(*args, **kwargs)\n  File \"C:\\Users\\DMS240~1\\AppData\\Local\\Temp/ipykernel_20128/753241018.py\", line 3, in <lambda>\nTypeError: unsupported operand type(s) for %: 'NoneType' and 'int'\n\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:456)\r\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:81)\r\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:64)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:410)\r\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\r\n\tat scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)\r\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\r\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\r\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\r\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\r\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)\r\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:260)\r\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:252)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:858)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:858)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:310)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\r\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:411)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:417)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1925)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1913)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1912)\r\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1912)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:948)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:948)\r\n\tat scala.Option.foreach(Option.scala:257)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:948)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2146)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2095)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2084)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:759)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2067)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2088)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2107)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2132)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:990)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:385)\r\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:989)\r\n\tat org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:304)\r\n\tat org.apache.spark.sql.Dataset$$anonfun$49.apply(Dataset.scala:3262)\r\n\tat org.apache.spark.sql.Dataset$$anonfun$49.apply(Dataset.scala:3260)\r\n\tat org.apache.spark.sql.Dataset$$anonfun$53.apply(Dataset.scala:3369)\r\n\tat org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:80)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:127)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:75)\r\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$withAction(Dataset.scala:3368)\r\n\tat org.apache.spark.sql.Dataset.collectToPython(Dataset.scala:3260)\r\n\tat sun.reflect.GeneratedMethodAccessor101.invoke(Unknown Source)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"C:\\work\\spark-2.4.8-bin-hadoop2.7\\python\\lib\\pyspark.zip\\pyspark\\worker.py\", line 377, in main\n  File \"C:\\work\\spark-2.4.8-bin-hadoop2.7\\python\\lib\\pyspark.zip\\pyspark\\worker.py\", line 372, in process\n  File \"C:\\work\\spark-2.4.8-bin-hadoop2.7\\python\\lib\\pyspark.zip\\pyspark\\serializers.py\", line 352, in dump_stream\n    self.serializer.dump_stream(self._batched(iterator), stream)\n  File \"C:\\work\\spark-2.4.8-bin-hadoop2.7\\python\\lib\\pyspark.zip\\pyspark\\serializers.py\", line 142, in dump_stream\n    for obj in iterator:\n  File \"C:\\work\\spark-2.4.8-bin-hadoop2.7\\python\\lib\\pyspark.zip\\pyspark\\serializers.py\", line 341, in _batched\n    for item in iterator:\n  File \"<string>\", line 1, in <lambda>\n  File \"C:\\work\\spark-2.4.8-bin-hadoop2.7\\python\\lib\\pyspark.zip\\pyspark\\worker.py\", line 85, in <lambda>\n  File \"C:\\work\\spark-2.4.8-bin-hadoop2.7\\python\\lib\\pyspark.zip\\pyspark\\util.py\", line 99, in wrapper\n    return f(*args, **kwargs)\n  File \"C:\\Users\\DMS240~1\\AppData\\Local\\Temp/ipykernel_20128/753241018.py\", line 3, in <lambda>\nTypeError: unsupported operand type(s) for %: 'NoneType' and 'int'\n\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:456)\r\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:81)\r\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:64)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:410)\r\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\r\n\tat scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)\r\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\r\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\r\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\r\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\r\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)\r\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:260)\r\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:252)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:858)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:858)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:310)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\r\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:411)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:417)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\t... 1 more\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\DMS240~1\\AppData\\Local\\Temp/ipykernel_20128/2536181623.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0morders_na\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\work\\spark-2.4.8-bin-hadoop2.7\\python\\pyspark\\sql\\dataframe.py\u001b[0m in \u001b[0;36mcollect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    533\u001b[0m         \"\"\"\n\u001b[0;32m    534\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcss\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 535\u001b[1;33m             \u001b[0msock_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollectToPython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    536\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msock_info\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBatchedSerializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPickleSerializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\work\\spark-2.4.8-bin-hadoop2.7\\python\\lib\\py4j-0.10.7-src.zip\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[1;32m-> 1257\u001b[1;33m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[0;32m   1258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1259\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\work\\spark-2.4.8-bin-hadoop2.7\\python\\pyspark\\sql\\utils.py\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\work\\spark-2.4.8-bin-hadoop2.7\\python\\lib\\py4j-0.10.7-src.zip\\py4j\\protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[0;32m    327\u001b[0m                     \u001b[1;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 328\u001b[1;33m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[0;32m    329\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o1021.collectToPython.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 72.0 failed 1 times, most recent failure: Lost task 0.0 in stage 72.0 (TID 5068, localhost, executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"C:\\work\\spark-2.4.8-bin-hadoop2.7\\python\\lib\\pyspark.zip\\pyspark\\worker.py\", line 377, in main\n  File \"C:\\work\\spark-2.4.8-bin-hadoop2.7\\python\\lib\\pyspark.zip\\pyspark\\worker.py\", line 372, in process\n  File \"C:\\work\\spark-2.4.8-bin-hadoop2.7\\python\\lib\\pyspark.zip\\pyspark\\serializers.py\", line 352, in dump_stream\n    self.serializer.dump_stream(self._batched(iterator), stream)\n  File \"C:\\work\\spark-2.4.8-bin-hadoop2.7\\python\\lib\\pyspark.zip\\pyspark\\serializers.py\", line 142, in dump_stream\n    for obj in iterator:\n  File \"C:\\work\\spark-2.4.8-bin-hadoop2.7\\python\\lib\\pyspark.zip\\pyspark\\serializers.py\", line 341, in _batched\n    for item in iterator:\n  File \"<string>\", line 1, in <lambda>\n  File \"C:\\work\\spark-2.4.8-bin-hadoop2.7\\python\\lib\\pyspark.zip\\pyspark\\worker.py\", line 85, in <lambda>\n  File \"C:\\work\\spark-2.4.8-bin-hadoop2.7\\python\\lib\\pyspark.zip\\pyspark\\util.py\", line 99, in wrapper\n    return f(*args, **kwargs)\n  File \"C:\\Users\\DMS240~1\\AppData\\Local\\Temp/ipykernel_20128/753241018.py\", line 3, in <lambda>\nTypeError: unsupported operand type(s) for %: 'NoneType' and 'int'\n\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:456)\r\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:81)\r\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:64)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:410)\r\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\r\n\tat scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)\r\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\r\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\r\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\r\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\r\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)\r\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:260)\r\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:252)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:858)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:858)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:310)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\r\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:411)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:417)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1925)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1913)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1912)\r\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1912)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:948)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:948)\r\n\tat scala.Option.foreach(Option.scala:257)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:948)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2146)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2095)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2084)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:759)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2067)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2088)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2107)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2132)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:990)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:385)\r\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:989)\r\n\tat org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:304)\r\n\tat org.apache.spark.sql.Dataset$$anonfun$49.apply(Dataset.scala:3262)\r\n\tat org.apache.spark.sql.Dataset$$anonfun$49.apply(Dataset.scala:3260)\r\n\tat org.apache.spark.sql.Dataset$$anonfun$53.apply(Dataset.scala:3369)\r\n\tat org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:80)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:127)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:75)\r\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$withAction(Dataset.scala:3368)\r\n\tat org.apache.spark.sql.Dataset.collectToPython(Dataset.scala:3260)\r\n\tat sun.reflect.GeneratedMethodAccessor101.invoke(Unknown Source)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"C:\\work\\spark-2.4.8-bin-hadoop2.7\\python\\lib\\pyspark.zip\\pyspark\\worker.py\", line 377, in main\n  File \"C:\\work\\spark-2.4.8-bin-hadoop2.7\\python\\lib\\pyspark.zip\\pyspark\\worker.py\", line 372, in process\n  File \"C:\\work\\spark-2.4.8-bin-hadoop2.7\\python\\lib\\pyspark.zip\\pyspark\\serializers.py\", line 352, in dump_stream\n    self.serializer.dump_stream(self._batched(iterator), stream)\n  File \"C:\\work\\spark-2.4.8-bin-hadoop2.7\\python\\lib\\pyspark.zip\\pyspark\\serializers.py\", line 142, in dump_stream\n    for obj in iterator:\n  File \"C:\\work\\spark-2.4.8-bin-hadoop2.7\\python\\lib\\pyspark.zip\\pyspark\\serializers.py\", line 341, in _batched\n    for item in iterator:\n  File \"<string>\", line 1, in <lambda>\n  File \"C:\\work\\spark-2.4.8-bin-hadoop2.7\\python\\lib\\pyspark.zip\\pyspark\\worker.py\", line 85, in <lambda>\n  File \"C:\\work\\spark-2.4.8-bin-hadoop2.7\\python\\lib\\pyspark.zip\\pyspark\\util.py\", line 99, in wrapper\n    return f(*args, **kwargs)\n  File \"C:\\Users\\DMS240~1\\AppData\\Local\\Temp/ipykernel_20128/753241018.py\", line 3, in <lambda>\nTypeError: unsupported operand type(s) for %: 'NoneType' and 'int'\n\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:456)\r\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:81)\r\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:64)\r\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:410)\r\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\r\n\tat scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)\r\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\r\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\r\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\r\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\r\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)\r\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:260)\r\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:252)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:858)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:858)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:310)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\r\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:411)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:417)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\t... 1 more\r\n"
     ]
    }
   ],
   "source": [
    "orders_na.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Order ID: string, Order Date: date, Order Year: string, Order Month: string]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order_my = order_deets_df.join(orders_na, on = \"Order ID\", how = \"left\")\\\n",
    ".select(f.concat_ws(\"-\", f.col(\"Order Month\"), f.col(\"Order Year\")).alias(\"Date\"), \"Category\", \"Amount\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "A46eiGbLzV9F"
   },
   "outputs": [],
   "source": [
    "order_my_grouped = order_my.groupBy([\"Date\", \"Category\"]).agg(sum(\"Amount\").alias(\"Amount\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hAYOlxSu3HtK",
    "outputId": "6f55ec00-a91e-4f7b-aa40-81d02ae6b20c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+-------+-------+--------+\n",
      "|  Date|   Category| Target| Amount|Achieved|\n",
      "+------+-----------+-------+-------+--------+\n",
      "|Feb-19|Electronics|16000.0|12593.0|      No|\n",
      "|Nov-18|Electronics| 9000.0|16651.0|     Yes|\n",
      "|Mar-19|  Furniture|11800.0|16659.0|     Yes|\n",
      "|Sep-18|Electronics| 9000.0| 7207.0|      No|\n",
      "|Aug-18|   Clothing|14000.0|11822.0|      No|\n",
      "+------+-----------+-------+-------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_achieved = f.udf(lambda x, y: \"No\" if x < y else \"Yes\")\n",
    "\n",
    "temp_target = target_df.select(f.col(\"Month of Order Date\").alias(\"Date\"), \"Category\", \"Target\")\n",
    "\n",
    "temp_target.join(order_my_grouped, on = [\"Date\", \"Category\"], how = \"inner\")\\\n",
    ".withColumn(\"Achieved\", get_achieved(f.col(\"Amount\"), f.col(\"Target\"))).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Wy6D08mhI3d"
   },
   "source": [
    "## **6. Best Customer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "PG-3E1vghODN"
   },
   "outputs": [],
   "source": [
    "order_amount = order_deets_df.groupBy(\"Order ID\").agg(sum(\"Amount\").alias(\"Amount\"))\n",
    "best_customer = orders_df.join(order_amount, on = \"Order ID\", how = \"inner\")\\\n",
    ".groupBy(\"CustomerName\").agg(sum(\"Amount\").alias(\"Total Purchase Amount\")).orderBy(\"Total Purchase Amount\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SGzcr4eVmQ8p",
    "outputId": "76c9b2ac-4d06-4518-9e10-2171c229059f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(CustomerName='Yaanvi', Total Purchase Amount=9177.0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_customer.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "PySpark.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
